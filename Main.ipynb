{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from wikipedia) (4.7.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from wikipedia) (2.21.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from beautifulsoup4->wikipedia) (1.7.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.8)\n",
      "Requirement already satisfied: requests in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (2.21.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests) (1.24.1)\n",
      "Collecting BeautilfulSoup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement BeautilfulSoup (from versions: )\n",
      "No matching distribution found for BeautilfulSoup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement time (from versions: )\n",
      "No matching distribution found for time\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia\n",
    "!pip install requests\n",
    "!pip install BeautilfulSoup\n",
    "!pip install time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\oburg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "#the goal is scrapping wikipedia in order to obtain information about citrus fruit\n",
    "#We take the description section of each one and then we will extract main info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "[[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "page_citrus = 'https://en.wikipedia.org/wiki/List_of_citrus_fruits'\n",
    "page_salads = 'https://en.wikipedia.org/wiki/List_of_leaf_vegetables'\n",
    "page_spices = 'https://en.wikipedia.org/wiki/List_of_culinary_herbs_and_spices'\n",
    "\n",
    "#A function that gets the URL of the page to be scraped\n",
    "#,gets the html content and uses BeautifulSoup to parse html content\n",
    "\n",
    "def make_soup(link):\n",
    "    get_page = requests.get(link)\n",
    "    html = get_page.content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return  soup\n",
    "#print(make_soup(page_spices))\n",
    "#this function create a list with all the link of the foods in a wikipedia list.\n",
    "def make_link_list(wiki_page_to_scrap):\n",
    "    link_table = []\n",
    "    soup = make_soup(wiki_page_to_scrap)\n",
    "    table = soup.find('table',{'class':'wikitable sortable'})\n",
    "    print(type(table))\n",
    "    if isinstance(table , bs4.element.Tag):        \n",
    "        species_table = table.find_all('a')      \n",
    "        for link in species_table:\n",
    "            species = link.get('title')\n",
    "            species = str(species)\n",
    "            if re.search('None', species) == None and re.search('Wikipedia' , species) == None :  \n",
    "                link_table.append(species)\n",
    "    else:\n",
    "        table = soup.find('div' , {'class':'div-col'})\n",
    "        species_table = table.find_all('li')\n",
    "        for text in species_table:\n",
    "            print(type(text))\n",
    "            species = text.find_all('#text')\n",
    "            \n",
    "            link_table.append(species)\n",
    "        \n",
    "        \n",
    "        print(link_table)\n",
    "  \n",
    "    return link_table\n",
    "    \n",
    "    \n",
    "#list_citrus = make_link_list(page_citrus)\n",
    "#print(list_citrus[:10])\n",
    "\n",
    "#list_salad = make_link_list(wiki_page_salads) \n",
    "#print(list_salad[:10])\n",
    "### Attention latin name were scrapped => tackle the traduction between latin & common name\n",
    "## maybe change in the \"make_link_list\"\n",
    "\n",
    "list_spices = make_link_list(page_spices)\n",
    "#print(list_spices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dictionary with the different categories of vegetables. \n",
    "#Categories will be: \n",
    "    #Stem Vegetables\n",
    "    #Leaves Vegetables\n",
    "    #Flowers Vegetables\n",
    "    #Bulb Vegetables\n",
    "    #Beans\n",
    "    #Roots Vegetables\n",
    "    #Tubers Vegetables\n",
    "    #Fruits Vegetables\n",
    "    #Fungi Vegetables\n",
    "\n",
    "\n",
    "vegetable_dict = {'Stem' : 0 , 'Leaves' : 0 , 'Flowers' : 0 , 'Bulb' : 0 , 'Beans' : 0 , 'Roots' : 0 , 'Tubers' : 0 , 'Fruits' : 0 , 'Fungi': 0 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
